{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2fdc972-653e-4674-b391-8c358ef98bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31529e13-06cc-4533-95cc-517c65e55e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c499f4f-42f6-4784-a93e-fb60245b11fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path='lite-model_movenet_singlepose_lightning_3.tflite')\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d2a51dc-2b5c-4bdb-9b86-a0e0baecc784",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_keypoints(frame, keypoints, confidence_threshold):\n",
    "    y, x, c = frame.shape\n",
    "    shaped = np.squeeze(np.multiply(keypoints, [y,x,1]))\n",
    "    \n",
    "    for kp in shaped:\n",
    "        ky, kx, kp_conf = kp\n",
    "        if kp_conf > confidence_threshold:\n",
    "            cv2.circle(frame, (int(kx), int(ky)), 4, (0,255,0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "390378c2-6197-499e-a8eb-782c350b2429",
   "metadata": {},
   "outputs": [],
   "source": [
    "EDGES = {\n",
    "    (0, 1): 'm',\n",
    "    (0, 2): 'c',\n",
    "    (1, 3): 'm',\n",
    "    (2, 4): 'c',\n",
    "    (0, 5): 'm',\n",
    "    (0, 6): 'c',\n",
    "    (5, 7): 'm',\n",
    "    (7, 9): 'm',\n",
    "    (6, 8): 'c',\n",
    "    (8, 10): 'c',\n",
    "    (5, 6): 'y',\n",
    "    (5, 11): 'm',\n",
    "    (6, 12): 'c',\n",
    "    (11, 12): 'y',\n",
    "    (11, 13): 'm',\n",
    "    (13, 15): 'm',\n",
    "    (12, 14): 'c',\n",
    "    (14, 16): 'c'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88e9130c-5111-46d8-94cb-24d97bd5d610",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_connections(frame, keypoints, edges, confidence_threshold):\n",
    "    y, x, c = frame.shape\n",
    "    shaped = np.squeeze(np.multiply(keypoints, [y,x,1]))\n",
    "    \n",
    "    for edge, color in edges.items():\n",
    "        p1, p2 = edge\n",
    "        y1, x1, c1 = shaped[p1]\n",
    "        y2, x2, c2 = shaped[p2]\n",
    "        \n",
    "        if (c1 > confidence_threshold) & (c2 > confidence_threshold):      \n",
    "            cv2.line(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0,0,255), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab96f885-3758-4808-b7f3-5f63ad89e246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nose 0, left eye 1, right eye 2, left ear 3, right ear 4, \n",
    "# left shoulder 5, right shoulder 6, left elbow 7, right elbow 8, \n",
    "# left wrist 9, right wrist 10, left hip 11, right hip 12, left knee 13, right knee 14, left ankle 15, right ankle 16\n",
    "# elbow, shoulder, hip, ankle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0943a0a-3f4f-43f5-ab15-60bf11a273df",
   "metadata": {},
   "outputs": [],
   "source": [
    "L_SHOULDER = 5\n",
    "R_SHOULDER = 6\n",
    "L_ELBOW = 7\n",
    "R_ELBOW = 8\n",
    "L_HIP = 11\n",
    "R_HIP = 12\n",
    "L_ANKLE = 15\n",
    "R_ANKLE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44ac9c79-7c8e-4744-8e4a-b6c90aaecb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angle(a,b,c):\n",
    "    # a is first angle, b is second angle, c is 3rd angle\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    c = np.array(b)\n",
    "    \n",
    "    radians = np.arctan2(c[1] - b[1], c[0] - b[0]) - np.arctan2(a[1] - b[1], a[0] - b[0])\n",
    "    angle = np.abs(radians * 180.0/np.pi)\n",
    "    \n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d04ccec5-79b7-4aaa-9e5a-26e4db9c70f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def find_angle(img_name, body1, body2, body3):\n",
    "    og_img = cv2.imread(os.path.join('images', img_name))\n",
    "    \"\"\"plt.imshow(og_img)\n",
    "    recolor = cv2.cvtColor(og_img, cv2.COLOR_BGR2RGB)\n",
    "    gray = cv2.cvtColor(og_img, cv2.COLOR_BGR2GRAY)\n",
    "    plt.imshow(recolor)\n",
    "    plt.show()\"\"\"\n",
    "    img = og_img.copy()\n",
    "    img = tf.image.resize_with_pad(np.expand_dims(img, axis=0), 192,192)\n",
    "    input_image = tf.cast(img, dtype=tf.float32)\n",
    "    \n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    \n",
    "    interpreter.set_tensor(input_details[0]['index'], np.array(input_image))\n",
    "    interpreter.invoke()\n",
    "    \n",
    "    keypoints_with_scores = interpreter.get_tensor(output_details[0]['index'])\n",
    "    angle = calculate_angle(keypoints_with_scores[0][0][body1], keypoints_with_scores[0][0][body2], keypoints_with_scores[0][0][body3])\n",
    "    \n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14cbb9b1-ac0b-4bdf-a862-81c538cefc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_angle(stage, angle, up_angle, down_angle):\n",
    "    if angle < down_angle:\n",
    "        stage = \"down\"\n",
    "    if angle > up_angle and stage =='down':\n",
    "        stage=\"up\"\n",
    "        return True, stage\n",
    "    return False, stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2d7eecd-b84e-468a-b83a-90a3e09fa683",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def count_jj(lhand_up_angle, lhand_down_angle, rhand_up_angle, rhand_down_angle, lhip_out_angle, lhip_in_angle, rhip_out_angle, rhip_in_angle):\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    frame_idx = 0\n",
    "    count = 0\n",
    "    jj = False\n",
    "    l_underarm_stage, r_underarm_stage, l_hip_stage, r_hip_stage = \"down\", \"down\", \"down\", \"down\"\n",
    "    # time.sleep(10)\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Reshape image\n",
    "        img = frame.copy()\n",
    "        img = tf.image.resize_with_pad(np.expand_dims(img, axis=0), 192,192)\n",
    "        input_image = tf.cast(img, dtype=tf.float32)\n",
    "\n",
    "        # Setup input and output \n",
    "        input_details = interpreter.get_input_details()\n",
    "        output_details = interpreter.get_output_details()\n",
    "\n",
    "        # Make predictions \n",
    "        interpreter.set_tensor(input_details[0]['index'], np.array(input_image))\n",
    "        interpreter.invoke()\n",
    "        keypoints_with_scores = interpreter.get_tensor(output_details[0]['index'])\n",
    "        # print(keypoints_with_scores)\n",
    "\n",
    "        # Rendering \n",
    "        draw_connections(frame, keypoints_with_scores, EDGES, 0.4)\n",
    "        draw_keypoints(frame, keypoints_with_scores, 0.4)\n",
    "\n",
    "        l_underarm_angle = calculate_angle(keypoints_with_scores[0][0][L_ELBOW], keypoints_with_scores[0][0][L_SHOULDER], keypoints_with_scores[0][0][L_HIP])\n",
    "        r_underarm_angle = calculate_angle(keypoints_with_scores[0][0][R_ELBOW], keypoints_with_scores[0][0][R_SHOULDER], keypoints_with_scores[0][0][R_HIP])\n",
    "        l_hip_angle = calculate_angle(keypoints_with_scores[0][0][L_SHOULDER], keypoints_with_scores[0][0][L_HIP], keypoints_with_scores[0][0][L_ANKLE])\n",
    "        r_hip_angle = calculate_angle(keypoints_with_scores[0][0][R_SHOULDER], keypoints_with_scores[0][0][R_HIP], keypoints_with_scores[0][0][R_ANKLE])\n",
    "\n",
    "        jj = True\n",
    "        result, l_underarm_stage = check_angle(l_underarm_stage, l_underarm_angle, lhand_up_angle, lhand_down_angle)\n",
    "        if (result == False):\n",
    "            larm = \"fail\"\n",
    "            jj = False\n",
    "        else:\n",
    "            larm = \"pass\"\n",
    "                \n",
    "        result, r_underarm_stage = check_angle(r_underarm_stage, r_underarm_angle, rhand_up_angle, rhand_down_angle)\n",
    "        if (result == False):\n",
    "            rarm = \"fail\"\n",
    "            jj = False\n",
    "        else:\n",
    "            rarm = \"pass\"\n",
    "                \n",
    "        result, l_hip_stage = check_angle(l_hip_stage, l_hip_angle, lhip_out_angle, lhip_in_angle)\n",
    "        if (result == False):\n",
    "            lhip = \"fail\"\n",
    "            jj = False\n",
    "        else:\n",
    "            lhip = \"pass\"\n",
    "                \n",
    "        result, r_hip_stage = check_angle(r_hip_stage, r_hip_angle, rhip_out_angle, rhip_in_angle)\n",
    "        if (result == False):\n",
    "            rhip = \"fail\"\n",
    "            jj = False\n",
    "        else:\n",
    "            rhip = \"pass\"\n",
    "                \n",
    "        if (jj):\n",
    "            count += 1\n",
    "        \n",
    "        # put angle\n",
    "        \"\"\"text_full = str(l_underarm_angle) + \" \" + str\n",
    "        cv2.putText(frame, text_full, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2, cv2.LINE_4)\n",
    "        \"\"\"    \n",
    "        # all jumping jacks\n",
    "        text_full = \"Jumping Jacks: \" + str(count)\n",
    "        cv2.putText(frame, text_full, (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_4)\n",
    "\n",
    "        text_full = \"Left arm: \" + larm\n",
    "        cv2.putText(frame, text_full, (50, 200), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_4)\n",
    "        \n",
    "        text_full =  \"Right arm: \" + rarm\n",
    "        cv2.putText(frame, text_full, (50, 275), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_4)\n",
    "        \n",
    "        text_full = \"Left hip: \" + lhip\n",
    "        cv2.putText(frame, text_full, (50, 350), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2,  cv2.LINE_4)\n",
    "        \n",
    "        text_full = \"Right hip: \" + rhip\n",
    "        cv2.putText(frame, text_full, (50, 425), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 2550, 255), 2, cv2.LINE_4)\n",
    "\n",
    "        cv2.imshow('MoveNet Lightning', frame)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF==ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eea9ec6a-0723-4057-a13e-b16041253950",
   "metadata": {},
   "outputs": [],
   "source": [
    "lhand_up_angle = find_angle(\"jjup.png\", L_ELBOW, L_SHOULDER, L_HIP)\n",
    "lhand_down_angle = find_angle(\"jjdown.png\", L_ELBOW, L_SHOULDER, L_HIP)\n",
    "rhand_up_angle = find_angle(\"jjup.png\", R_ELBOW, R_SHOULDER, R_HIP)\n",
    "rhand_down_angle = find_angle(\"jjdown.png\", R_ELBOW, R_SHOULDER, R_HIP)\n",
    "lhip_out_angle = find_angle(\"jjup.png\", L_SHOULDER, L_HIP, L_ANKLE)\n",
    "lhip_in_angle = find_angle(\"jjdown.png\", L_SHOULDER, L_HIP, L_ANKLE)\n",
    "rhip_out_angle = find_angle(\"jjup.png\", R_SHOULDER, R_HIP, R_ANKLE)\n",
    "rhip_in_angle = find_angle(\"jjdown.png\", R_SHOULDER, R_HIP, R_ANKLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ab0aa55-8dd4-4d3a-9dec-002e6c742aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_jj(lhand_up_angle, lhand_down_angle, rhand_up_angle, rhand_down_angle, lhip_out_angle, lhip_in_angle, rhip_out_angle, rhip_in_angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ff0171-b88a-4c0d-90ce-7bad0e794bce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "52cd2d2f-ffb0-41ea-b11b-b3085bc5d5bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def count_jj(lhand_up_angle, lhand_down_angle, rhand_up_angle, rhand_down_angle, lhip_out_angle, lhip_in_angle, rhip_out_angle, rhip_in_angle):\\n    cap = cv2.VideoCapture(0)\\n    frame_idx = 0\\n    stage = \"down\"\\n    count = 0\\n    while cap.isOpened():\\n        ret, frame = cap.read()\\n\\n        # Reshape image\\n        img = frame.copy()\\n        img = tf.image.resize_with_pad(np.expand_dims(img, axis=0), 192,192)\\n        input_image = tf.cast(img, dtype=tf.float32)\\n\\n        # Setup input and output \\n        input_details = interpreter.get_input_details()\\n        output_details = interpreter.get_output_details()\\n\\n        # Make predictions \\n        interpreter.set_tensor(input_details[0][\\'index\\'], np.array(input_image))\\n        interpreter.invoke()\\n        keypoints_with_scores = interpreter.get_tensor(output_details[0][\\'index\\'])\\n        # print(keypoints_with_scores)\\n\\n        # Rendering \\n        draw_connections(frame, keypoints_with_scores, EDGES, 0.4)\\n        draw_keypoints(frame, keypoints_with_scores, 0.4)\\n\\n        underarm_angle = calculate_angle(keypoints_with_scores[0][0][L_ELBOW], keypoints_with_scores[0][0][L_SHOULDER], keypoints_with_scores[0][0][L_HIP])\\n\\n        if underarm_angle < down_angle:\\n            stage = \"down\"\\n        if underarm_angle > up_angle and stage ==\\'down\\':\\n            stage=\"up\"\\n            count +=1\\n        # put angle and stage\\n        text_full = str(underarm_angle) + \" \" + stage\\n        cv2.putText(frame,  \\n                    text_full,  \\n                    (50, 50),  \\n                    cv2.FONT_HERSHEY_SIMPLEX, 1,  \\n                    (0, 255, 255),  \\n                    2,  \\n                    cv2.LINE_4)\\n            \\n        # all jumping jacks\\n        text_full = \"Jumping Jacks: \" + str(count)\\n            \\n        cv2.putText(frame,  \\n                    text_full,  \\n                    (50, 100),  \\n                    cv2.FONT_HERSHEY_SIMPLEX, 1,  \\n                    (255, 0, 255),  \\n                    2,  \\n                    cv2.LINE_4)\\n\\n        # left & rt hand\\n        text_full = stage + str(count)\\n\\n        cv2.putText(frame,  \\n                    text_full,  \\n                    (50, 100),  \\n                    cv2.FONT_HERSHEY_SIMPLEX, 1,  \\n                    (255, 0, 255),  \\n                    2,  \\n                    cv2.LINE_4)\\n        \\n        # left % rt leg\\n        text_full = \"left: \" str(left_leg_count) + \" right: \" + str(rt_leg_count)\\n\\n        cv2.putText(frame,  \\n                    text_full,  \\n                    (50, 100),  \\n                    cv2.FONT_HERSHEY_SIMPLEX, 1,  \\n                    (255, 0, 255),  \\n                    2,  \\n                    cv2.LINE_4)\\n\\n        cv2.imshow(\\'MoveNet Lightning\\', frame)\\n\\n        if cv2.waitKey(10) & 0xFF==ord(\\'q\\'):\\n            break\\n\\n    cap.release()\\n    cv2.destroyAllWindows()'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def count_jj(lhand_up_angle, lhand_down_angle, rhand_up_angle, rhand_down_angle, lhip_out_angle, lhip_in_angle, rhip_out_angle, rhip_in_angle):\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    frame_idx = 0\n",
    "    stage = \"down\"\n",
    "    count = 0\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Reshape image\n",
    "        img = frame.copy()\n",
    "        img = tf.image.resize_with_pad(np.expand_dims(img, axis=0), 192,192)\n",
    "        input_image = tf.cast(img, dtype=tf.float32)\n",
    "\n",
    "        # Setup input and output \n",
    "        input_details = interpreter.get_input_details()\n",
    "        output_details = interpreter.get_output_details()\n",
    "\n",
    "        # Make predictions \n",
    "        interpreter.set_tensor(input_details[0]['index'], np.array(input_image))\n",
    "        interpreter.invoke()\n",
    "        keypoints_with_scores = interpreter.get_tensor(output_details[0]['index'])\n",
    "        # print(keypoints_with_scores)\n",
    "\n",
    "        # Rendering \n",
    "        draw_connections(frame, keypoints_with_scores, EDGES, 0.4)\n",
    "        draw_keypoints(frame, keypoints_with_scores, 0.4)\n",
    "\n",
    "        underarm_angle = calculate_angle(keypoints_with_scores[0][0][L_ELBOW], keypoints_with_scores[0][0][L_SHOULDER], keypoints_with_scores[0][0][L_HIP])\n",
    "\n",
    "        if underarm_angle < down_angle:\n",
    "            stage = \"down\"\n",
    "        if underarm_angle > up_angle and stage =='down':\n",
    "            stage=\"up\"\n",
    "            count +=1\n",
    "        # put angle and stage\n",
    "        text_full = str(underarm_angle) + \" \" + stage\n",
    "        cv2.putText(frame,  \n",
    "                    text_full,  \n",
    "                    (50, 50),  \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1,  \n",
    "                    (0, 255, 255),  \n",
    "                    2,  \n",
    "                    cv2.LINE_4)\n",
    "            \n",
    "        # all jumping jacks\n",
    "        text_full = \"Jumping Jacks: \" + str(count)\n",
    "            \n",
    "        cv2.putText(frame,  \n",
    "                    text_full,  \n",
    "                    (50, 100),  \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1,  \n",
    "                    (255, 0, 255),  \n",
    "                    2,  \n",
    "                    cv2.LINE_4)\n",
    "\n",
    "        # left & rt hand\n",
    "        text_full = stage + str(count)\n",
    "\n",
    "        cv2.putText(frame,  \n",
    "                    text_full,  \n",
    "                    (50, 100),  \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1,  \n",
    "                    (255, 0, 255),  \n",
    "                    2,  \n",
    "                    cv2.LINE_4)\n",
    "        \n",
    "        # left % rt leg\n",
    "        text_full = \"left: \" str(left_leg_count) + \" right: \" + str(rt_leg_count)\n",
    "\n",
    "        cv2.putText(frame,  \n",
    "                    text_full,  \n",
    "                    (50, 100),  \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1,  \n",
    "                    (255, 0, 255),  \n",
    "                    2,  \n",
    "                    cv2.LINE_4)\n",
    "\n",
    "        cv2.imshow('MoveNet Lightning', frame)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF==ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f18cc71-77c8-43d5-b9e4-ca5386a2cf58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
